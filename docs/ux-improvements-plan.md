# TaskFlow UX Improvements Plan

**Created**: 2026-01-02
**Status**: Pending Implementation

---

## üìã Overview

This document outlines critical UX improvements needed for PRD creation and architecture generation commands based on user feedback and code analysis.

---

## üéØ Goals

1. Provide real-time visual feedback during AI operations
2. Improve question display and user input interfaces
3. Add debugging/logging capabilities for AI API calls
4. Implement session recovery for interrupted workflows
5. Fix placeholder file conflicts in generate-arch command
6. Enforce concise output limits for architecture files (max 125 lines each)

---

## üö® Critical Issues Summary

### Issue #1: No Visual Feedback During AI API Calls
**Impact**: High - Users think the system has frozen
**Files**: `packages/core/src/commands/prd/create.ts`
**Lines**: 122, 249, 266, 284-293, 326-341

### Issue #2: Poor Question Formatting & Input UX
**Impact**: Medium - Confusing user experience
**Files**: `packages/core/src/commands/prd/create.ts`
**Lines**: 456-495

### Issue #3: No AI API Call Logging
**Impact**: Medium - Cannot debug or audit AI interactions
**Files**: All LLM-related commands

### Issue #4: No Session Recovery
**Impact**: Medium - Lost work if interrupted
**Files**: `packages/core/src/lib/prd-interactive-session.ts`

### Issue #5: Generate-Arch Placeholder File Conflict (BLOCKING)
**Impact**: Critical - Command fails after init
**Files**:
- `packages/core/src/commands/init.ts:184-219`
- `packages/core/src/commands/prd/generate-arch.ts:68-89`

### Issue #6: Generate-Arch No Progress Feedback
**Impact**: High - Users think the system has frozen
**Files**: `packages/core/src/commands/prd/generate-arch.ts:354-590`

### Issue #7: Architecture Files Too Long (NEW)
**Impact**: Medium - Generated files are 250+ lines, should be max 125 lines each
**Files**: `packages/core/src/commands/prd/generate-arch.ts:434-509, 513-590`
**Problem**: Current prompts don't enforce length limits, resulting in verbose output

---

## üìÖ Phased Implementation Plan

### **Phase 1: Critical Blockers** (Priority: URGENT)

Fix issues that prevent commands from working.

#### Task 1.1: Fix Generate-Arch Placeholder File Conflict
**Estimated Effort**: Small
**Files to Modify**:
- `packages/core/src/commands/prd/generate-arch.ts`
- `packages/core/src/commands/init.ts`

**Solution**: Don't Create Placeholders in Init (Recommended)

**Implementation**:
```typescript
// File: packages/core/src/commands/init.ts
// Line 184-219: Comment out project template file creation

// BEFORE:
for (const [_key, sourcePath] of Object.entries(TEMPLATE_FILES.project)) {
  // Creates coding-standards.md and architecture-rules.md placeholders
  ...
}

// AFTER:
// Skip project template files - let generate-arch create them
// Project template files (coding-standards.md, architecture-rules.md) will be
// generated by 'taskflow prd generate-arch' command after PRD creation

console.log(TerminalFormatter.info(
  "Note: Run 'taskflow prd generate-arch <prd-file>' after creating a PRD " +
  "to generate coding-standards.md and architecture-rules.md"
));
```

**Rationale**:
- Simpler workflow
- No risk of accidentally overwriting custom files
- Generate-arch is the proper way to create these files from PRD context

---

#### Task 1.2: Enforce Length Limits on Architecture Files
**Estimated Effort**: Small
**Files to Modify**:
- `packages/core/src/commands/prd/generate-arch.ts:434-509` (generateCodingStandards)
- `packages/core/src/commands/prd/generate-arch.ts:513-590` (generateArchitectureRules)

**Problem**: Generated files are 250+ lines per file. Should be max 125 lines each for conciseness.

**Implementation**:

```typescript
// File: packages/core/src/commands/prd/generate-arch.ts

private async generateCodingStandards(
  prdContent: string,
  contextFiles: Array<{ name: string; content: string }>,
  instructions?: string,
): Promise<string> {
  if (!this.llmProvider) {
    throw new LLMRequiredError("LLM provider not available");
  }

  const llmProvider = this.llmProvider;

  const systemPrompt = `You are an expert software architect tasked with creating project-specific coding standards.

Your mission is to analyze the PRD and create a CONCISE coding-standards.md file that will guide all development work.

CRITICAL LENGTH REQUIREMENT:
- OUTPUT MUST NOT EXCEED 125 LINES TOTAL
- Be extremely concise and direct
- Use bullet points, not paragraphs
- Include only the most essential rules
- Avoid repetition and examples unless absolutely critical

CRITICAL RULES:
1. DO NOT invent patterns - base standards on real-world best practices
2. DO NOT write generic standards - be specific to the project's needs
3. DO include concrete examples ONLY when critical for understanding
4. DO make rules enforceable and measurable
5. DO align with the PRD requirements and technology stack
6. DO keep each section under 20 lines maximum

Required sections (MUST fit in 125 lines total):
1. File Organization (max 20 lines)
2. Code Style (max 20 lines)
3. TypeScript Usage (max 20 lines)
4. Error Handling (max 20 lines)
5. Testing (max 20 lines)
6. Documentation (max 20 lines)

For each section, provide:
- Clear, specific rules in bullet points
- ONLY 1-2 examples if absolutely necessary
- NO lengthy explanations

FORMAT REQUIREMENTS:
- Use compact bullet points (‚Ä¢) not numbered lists
- One rule per line
- No blank lines between bullets in same section
- Maximum 2 blank lines between sections
- No verbose introductions or conclusions

EXAMPLE OF CONCISE FORMAT:
## File Organization
‚Ä¢ Components: src/components/{FeatureName}/index.tsx
‚Ä¢ Tests: src/components/{FeatureName}/__tests__/index.test.tsx
‚Ä¢ Hooks: src/hooks/use{HookName}.ts
‚Ä¢ Utils: src/utils/{category}/{functionName}.ts

${instructions ? `\nAdditional instructions: ${instructions}` : ""}

REMEMBER: MAXIMUM 125 LINES TOTAL. Count every line including headers and blank lines.`;

  const contextSection = contextFiles
    .map(
      (file) => `
=== ${file.name} ===
${file.content}
`,
    )
    .join("\n");

  const userPrompt = `Generate a comprehensive but CONCISE coding-standards.md file (MAX 125 lines) based on the following PRD:

=== PRD ===
${prdContent}

${contextSection}

Create a detailed but CONCISE coding-standards.md file with all required sections.
CRITICAL: Stay under 125 lines total.
Output ONLY the markdown content, no additional commentary.`;

  const messages = [
    { role: "system" as const, content: systemPrompt },
    { role: "user" as const, content: userPrompt },
  ];

  const options = {
    maxTokens: 2000, // Reduced from 4000 to enforce brevity
    temperature: 0.3,
  };

  const response = await this.retryWithBackoff(() =>
    llmProvider.generate(messages, options),
  );

  // Track cost
  this.costTracker.trackUsage(response);

  // Validate line count
  const lineCount = response.content.split('\n').length;
  if (lineCount > 125) {
    console.warn(TerminalFormatter.warning(
      `Generated coding-standards.md has ${lineCount} lines (exceeds 125 line limit). ` +
      `Consider reviewing and condensing.`
    ));
  }

  return response.content;
}

private async generateArchitectureRules(
  prdContent: string,
  contextFiles: Array<{ name: string; content: string }>,
  instructions?: string,
): Promise<string> {
  if (!this.llmProvider) {
    throw new LLMRequiredError("LLM provider not available");
  }

  const llmProvider = this.llmProvider;

  const systemPrompt = `You are an expert software architect tasked with creating project-specific architecture rules.

Your mission is to analyze the PRD and create a CONCISE architecture-rules.md file that will guide all architectural decisions.

CRITICAL LENGTH REQUIREMENT:
- OUTPUT MUST NOT EXCEED 125 LINES TOTAL
- Be extremely concise and direct
- Use bullet points, not paragraphs
- Include only the most essential rules
- Avoid repetition and examples unless absolutely critical

CRITICAL RULES:
1. DO NOT invent architecture - base rules on the PRD requirements
2. DO NOT write generic rules - be specific to the project's architecture
3. DO include concrete examples ONLY when critical for understanding
4. DO make rules enforceable and measurable
5. DO align with the PRD's technical requirements
6. DO keep each section under 18 lines maximum

Required sections (MUST fit in 125 lines total):
1. Project Structure (max 18 lines)
2. Dependency Rules (max 18 lines)
3. Data Flow (max 18 lines)
4. API Design (max 18 lines)
5. Security (max 18 lines)
6. Performance (max 18 lines)
7. Feature-Specific Rules (max 18 lines)

For each section, provide:
- Clear architectural constraints in bullet points
- Allowed and forbidden patterns (concisely)
- NO lengthy explanations

FORMAT REQUIREMENTS:
- Use compact bullet points (‚Ä¢) not numbered lists
- One rule per line
- No blank lines between bullets in same section
- Maximum 2 blank lines between sections
- No verbose introductions or conclusions

EXAMPLE OF CONCISE FORMAT:
## Dependency Rules
‚Ä¢ UI components can import: hooks, utils, types
‚Ä¢ UI components CANNOT import: services, API clients
‚Ä¢ Services can import: utils, types, API clients
‚Ä¢ Circular dependencies are forbidden

${instructions ? `\nAdditional instructions: ${instructions}` : ""}

REMEMBER: MAXIMUM 125 LINES TOTAL. Count every line including headers and blank lines.`;

  const contextSection = contextFiles
    .map(
      (file) => `
=== ${file.name} ===
${file.content}
`,
    )
    .join("\n");

  const userPrompt = `Generate a comprehensive but CONCISE architecture-rules.md file (MAX 125 lines) based on the following PRD:

=== PRD ===
${prdContent}

${contextSection}

Create a detailed but CONCISE architecture-rules.md file with all required sections.
CRITICAL: Stay under 125 lines total.
Output ONLY the markdown content, no additional commentary.`;

  const messages = [
    { role: "system" as const, content: systemPrompt },
    { role: "user" as const, content: userPrompt },
  ];

  const options = {
    maxTokens: 2000, // Reduced from 4000 to enforce brevity
    temperature: 0.3,
  };

  const response = await this.retryWithBackoff(() =>
    llmProvider.generate(messages, options),
  );

  // Track cost
  this.costTracker.trackUsage(response);

  // Validate line count
  const lineCount = response.content.split('\n').length;
  if (lineCount > 125) {
    console.warn(TerminalFormatter.warning(
      `Generated architecture-rules.md has ${lineCount} lines (exceeds 125 line limit). ` +
      `Consider reviewing and condensing.`
    ));
  }

  return response.content;
}
```

**Key Changes**:
1. Added explicit "MAXIMUM 125 LINES" requirement in system prompts
2. Emphasized conciseness: "Be extremely concise and direct"
3. Changed format to bullet points instead of verbose paragraphs
4. Reduced max section lengths (18-20 lines per section)
5. Reduced maxTokens from 4000 to 2000 to enforce brevity
6. Added line count validation and warning after generation
7. Removed encouragement for lengthy examples
8. Added explicit formatting requirements

**Expected Output Format**:
- coding-standards.md: ~100-125 lines (6 sections √ó ~20 lines)
- architecture-rules.md: ~100-125 lines (7 sections √ó ~18 lines)

---

### **Phase 2: Visual Feedback** (Priority: HIGH)

Add progress indicators and status updates for long-running operations.

#### Task 2.1: Add Spinner/Progress Library
**Estimated Effort**: Small
**Files to Create/Modify**:
- `packages/core/src/lib/progress-indicator.ts` (new)
- `package.json` (add dependency)

**Implementation**:

```bash
# Add ora for spinners
pnpm add ora
```

```typescript
// File: packages/core/src/lib/progress-indicator.ts
import ora, { Ora } from 'ora';

export class ProgressIndicator {
  private spinner: Ora | null = null;

  start(message: string): void {
    this.spinner = ora(message).start();
  }

  update(message: string): void {
    if (this.spinner) {
      this.spinner.text = message;
    }
  }

  succeed(message: string): void {
    if (this.spinner) {
      this.spinner.succeed(message);
      this.spinner = null;
    }
  }

  fail(message: string): void {
    if (this.spinner) {
      this.spinner.fail(message);
      this.spinner = null;
    }
  }

  stop(): void {
    if (this.spinner) {
      this.spinner.stop();
      this.spinner = null;
    }
  }
}
```

#### Task 2.2: Add Progress to PRD Create Command
**Estimated Effort**: Medium
**Files to Modify**:
- `packages/core/src/commands/prd/create.ts`

**Implementation**:

```typescript
// File: packages/core/src/commands/prd/create.ts

import { ProgressIndicator } from '../../lib/progress-indicator.js';

private async generateQuestions(title: string, summary: string): Promise<Question[]> {
  const progress = new ProgressIndicator();

  progress.start('Analyzing requirements and generating questions...');

  try {
    const systemPrompt = this.buildSystemPromptForQuestions();
    const userPrompt = this.buildQuestionPrompt(title, summary);

    const response = await this.llmProvider?.generate(
      [
        { role: "system", content: systemPrompt },
        { role: "user", content: userPrompt },
      ],
      {
        maxTokens: 2000,
        temperature: 0.7,
      },
    );

    if (!response) {
      progress.fail('Failed to generate questions');
      return [];
    }

    progress.succeed('Questions generated');
    return this.parseAllQuestions(response.content);
  } catch (error) {
    progress.fail('Error generating questions');
    throw error;
  }
}

private async generateFinalPRD(
  title: string,
  summary: string,
  questions: Question[],
  answers: string[],
  paths: ReturnType<ConfigLoader["getPaths"]>,
): Promise<string> {
  const progress = new ProgressIndicator();

  progress.start('Generating PRD document...');

  try {
    const systemPrompt = this.buildSystemPromptForPRD(paths);
    const userPrompt = this.buildPRDPrompt(title, summary, questions, answers);

    const response = await this.llmProvider?.generate(
      [
        { role: "system", content: systemPrompt },
        { role: "user", content: userPrompt },
      ],
      {
        maxTokens: 4000,
        temperature: 0.7,
      },
    );

    if (!response) {
      progress.fail('Failed to generate PRD');
      throw new Error("Failed to generate PRD");
    }

    progress.succeed('PRD generated successfully');
    return response.content;
  } catch (error) {
    progress.fail('Error generating PRD');
    throw error;
  }
}
```

#### Task 2.3: Add Progress to Generate-Arch Command
**Estimated Effort**: Medium
**Files to Modify**:
- `packages/core/src/commands/prd/generate-arch.ts`

**Implementation**:

```typescript
// File: packages/core/src/commands/prd/generate-arch.ts

import { ProgressIndicator } from '../../lib/progress-indicator.js';

private async generateStandardsWithLLM(
  prdContent: string,
  prdFile: string,
  refDir: string,
  instructions?: string,
): Promise<CommandResult> {
  if (!this.llmProvider) {
    throw new LLMRequiredError("LLM provider not available");
  }

  const progress = new ProgressIndicator();

  // Load context files
  progress.start('Loading context files...');
  const contextFiles: { name: string; content: string }[] = [];

  const prdGeneratorPath = getRefFilePath(refDir, REF_FILES.prdGenerator);
  if (fs.existsSync(prdGeneratorPath)) {
    contextFiles.push({
      name: REF_FILES.prdGenerator,
      content: fs.readFileSync(prdGeneratorPath, "utf-8"),
    });
  }

  const aiProtocolPath = getRefFilePath(refDir, REF_FILES.aiProtocol);
  if (fs.existsSync(aiProtocolPath)) {
    contextFiles.push({
      name: REF_FILES.aiProtocol,
      content: fs.readFileSync(aiProtocolPath, "utf-8"),
    });
  }
  progress.succeed('Context files loaded');

  // Generate coding-standards.md
  const codingStandardsPath = getRefFilePath(
    refDir,
    REF_FILES.codingStandards,
  );

  progress.start('Generating coding-standards.md (1/2)...');
  const codingStandardsContent = await this.generateCodingStandards(
    prdContent,
    contextFiles,
    instructions,
  );
  progress.succeed('Generated coding-standards.md (max 125 lines)');

  // Generate architecture-rules.md
  const architectureRulesPath = getRefFilePath(
    refDir,
    REF_FILES.architectureRules,
  );

  progress.start('Generating architecture-rules.md (2/2)...');
  const architectureRulesContent = await this.generateArchitectureRules(
    prdContent,
    contextFiles,
    instructions,
  );
  progress.succeed('Generated architecture-rules.md (max 125 lines)');

  // Write files
  progress.start('Writing files to disk...');
  fs.writeFileSync(codingStandardsPath, codingStandardsContent, "utf-8");
  fs.writeFileSync(architectureRulesPath, architectureRulesContent, "utf-8");
  progress.succeed('Files saved successfully');

  return this.success(
    [
      `‚úì Generated coding-standards.md`,
      `‚úì Generated architecture-rules.md`,
      "",
      "Files created:",
      `  - ${codingStandardsPath}`,
      `  - ${architectureRulesPath}`,
    ].join("\n"),
    [
      "Next steps:",
      "",
      "1. Review the generated files and make adjustments if needed",
      "",
      "2. Generate tasks from PRD:",
      `   taskflow tasks generate ${prdFile}`,
    ].join("\n"),
  );
}
```

---

### **Phase 3: Enhanced UX** (Priority: MEDIUM)

Improve formatting and user input interfaces.

#### Task 3.1: Add Rich Terminal Formatting
**Estimated Effort**: Small
**Files to Create/Modify**:
- `packages/core/src/lib/terminal-formatter.ts` (new)
- `package.json` (add dependency)

**Implementation**:

```bash
# Add chalk for colors
pnpm add chalk
```

```typescript
// File: packages/core/src/lib/terminal-formatter.ts
import chalk from 'chalk';

export class TerminalFormatter {
  static header(text: string): string {
    return chalk.bold.cyan(`\n${'‚ïê'.repeat(60)}\n${text}\n${'‚ïê'.repeat(60)}\n`);
  }

  static section(title: string): string {
    return chalk.bold.yellow(`\n${title}\n${'‚îÄ'.repeat(40)}`);
  }

  static question(number: number, text: string): string {
    return chalk.bold.white(`\n${number}. ${text}`);
  }

  static option(text: string): string {
    return chalk.gray(`   ${text}`);
  }

  static prompt(text: string): string {
    return chalk.green(`\n${text}\n> `);
  }

  static success(text: string): string {
    return chalk.green(`‚úì ${text}`);
  }

  static error(text: string): string {
    return chalk.red(`‚úó ${text}`);
  }

  static warning(text: string): string {
    return chalk.yellow(`‚ö† ${text}`);
  }

  static info(text: string): string {
    return chalk.blue(`‚Ñπ ${text}`);
  }
}
```

#### Task 3.2: Improve Question Display
**Estimated Effort**: Small
**Files to Modify**:
- `packages/core/src/commands/prd/create.ts:456-467`

**Implementation**:

```typescript
// File: packages/core/src/commands/prd/create.ts

import { TerminalFormatter } from '../../lib/terminal-formatter.js';
import chalk from 'chalk';

private displayQuestions(questions: Question[]): void {
  console.log(TerminalFormatter.header('CLARIFYING QUESTIONS'));

  console.log(chalk.dim('Please answer the following questions to help generate a comprehensive PRD.\n'));

  for (const q of questions) {
    console.log(TerminalFormatter.question(q.number, q.text));

    if (q.options && q.options.length > 0) {
      for (const opt of q.options) {
        console.log(TerminalFormatter.option(opt));
      }
    }

    if (q.type === 'multiple-choice') {
      console.log(chalk.dim(`   Type: Multiple Choice`));
    } else {
      console.log(chalk.dim(`   Type: Open-ended`));
    }
  }

  console.log(chalk.bold.white('\n' + '‚îÄ'.repeat(60)));
}
```

#### Task 3.3: Improve Answer Input UX
**Estimated Effort**: Medium
**Files to Modify**:
- `packages/core/src/commands/prd/create.ts:473-495`

**Implementation**:

```typescript
// File: packages/core/src/commands/prd/create.ts

private async getUserAnswersAllAtOnce(questions: Question[]): Promise<string[]> {
  const rl = readline.createInterface({
    input: process.stdin,
    output: process.stdout,
  });

  console.log(TerminalFormatter.section('HOW TO ANSWER'));
  console.log(chalk.dim('You can provide answers in the following formats:'));
  console.log(chalk.white('  ‚Ä¢ Multiple choice: 1A, 2C, 3B'));
  console.log(chalk.white('  ‚Ä¢ Open-ended: 3: My detailed answer here'));
  console.log(chalk.white('  ‚Ä¢ Mixed: 1A, 2C, 3: My answer, 4B\n'));

  console.log(TerminalFormatter.prompt('Enter your answers:'));

  const answerText = await new Promise<string>((resolve) => {
    rl.question('', (ans) => {
      rl.close();
      resolve(ans.trim());
    });
  });

  // Validate answers
  if (!answerText) {
    console.log(TerminalFormatter.error('No answers provided. Please try again.'));
    return this.getUserAnswersAllAtOnce(questions);
  }

  console.log(TerminalFormatter.success(`Received answers for ${questions.length} questions`));

  return [answerText];
}
```

---

### **Phase 4: Debugging & Observability** (Priority: MEDIUM)

Add logging and debugging capabilities.

#### Task 4.1: Create AI Call Logger
**Estimated Effort**: Medium
**Files to Create**:
- `packages/core/src/lib/ai-call-logger.ts` (new)

**Implementation**:

```typescript
// File: packages/core/src/lib/ai-call-logger.ts
import fs from 'node:fs';
import path from 'node:path';

export interface AICallLog {
  timestamp: string;
  command: string;
  provider: string;
  model: string;
  prompt: {
    system: string;
    user: string;
  };
  response: {
    content: string;
    usage?: {
      promptTokens: number;
      completionTokens: number;
      totalTokens: number;
    };
  };
  duration: number; // milliseconds
  error?: string;
}

export class AICallLogger {
  private logDir: string;
  private isEnabled: boolean;

  constructor(projectRoot: string, enabled: boolean = false) {
    this.logDir = path.join(projectRoot, '.taskflow', 'logs', 'ai-calls');
    this.isEnabled = enabled;

    if (this.isEnabled) {
      this.ensureLogDir();
    }
  }

  private ensureLogDir(): void {
    if (!fs.existsSync(this.logDir)) {
      fs.mkdirSync(this.logDir, { recursive: true });
    }
  }

  async logCall(log: AICallLog): Promise<void> {
    if (!this.isEnabled) return;

    const date = new Date().toISOString().split('T')[0];
    const logFile = path.join(this.logDir, `${date}.jsonl`);

    const logLine = JSON.stringify(log) + '\n';

    fs.appendFileSync(logFile, logLine, 'utf-8');
  }

  async logError(command: string, error: Error): Promise<void> {
    if (!this.isEnabled) return;

    const log: AICallLog = {
      timestamp: new Date().toISOString(),
      command,
      provider: 'unknown',
      model: 'unknown',
      prompt: { system: '', user: '' },
      response: { content: '' },
      duration: 0,
      error: error.message,
    };

    await this.logCall(log);
  }

  enable(): void {
    this.isEnabled = true;
    this.ensureLogDir();
  }

  disable(): void {
    this.isEnabled = false;
  }
}
```

#### Task 4.2: Integrate AI Logger with Commands
**Estimated Effort**: Medium
**Files to Modify**:
- `packages/core/src/commands/base.ts`
- `packages/core/src/commands/prd/create.ts`
- `packages/core/src/commands/prd/generate-arch.ts`

**Usage**:
```bash
# Enable debug mode with AI call logging
TASKFLOW_DEBUG=true taskflow prd create my-feature

# Logs will be saved to:
# .taskflow/logs/ai-calls/2026-01-02.jsonl
```

---

### **Phase 5: Session Recovery** (Priority: LOW)

Implement session persistence and recovery (deferred - nice to have).

---

## üéØ Success Criteria

### Phase 1 Success
- [x] Placeholder file conflict identified
- [ ] `taskflow prd generate-arch` works after `taskflow init`
- [ ] No "files already exist" error on fresh project
- [ ] Architecture files are max 125 lines each
- [ ] AI prompts enforce conciseness

### Phase 2 Success
- [ ] All LLM operations show spinner/progress indicator
- [ ] Users can see what step is currently executing
- [ ] No more "frozen terminal" experience
- [ ] Progress shows for both file generations

### Phase 3 Success
- [ ] Questions are displayed with colors and clear hierarchy
- [ ] Answer input has helpful instructions and examples
- [ ] Terminal output is visually appealing

### Phase 4 Success
- [ ] AI calls are logged when debug mode is enabled
- [ ] Logs include prompts, responses, and token usage
- [ ] Logs are saved to `.taskflow/logs/ai-calls/`

---

## üì¶ Dependencies to Add

```bash
# Phase 2
pnpm add ora

# Phase 3
pnpm add chalk
```

---

## üîß Testing Checklist

### Phase 1 Testing
- [ ] Fresh `taskflow init` ‚Üí `taskflow prd create` ‚Üí `taskflow prd generate-arch` works
- [ ] coding-standards.md is under 125 lines
- [ ] architecture-rules.md is under 125 lines
- [ ] Files are concise but comprehensive
- [ ] No placeholder files created during init

### Phase 2 Testing
- [ ] Spinner shows during question generation
- [ ] Spinner shows during PRD generation
- [ ] Spinner shows during coding-standards generation (with 1/2 indicator)
- [ ] Spinner shows during architecture-rules generation (with 2/2 indicator)
- [ ] Progress messages are clear and accurate
- [ ] Success messages confirm completion

### Phase 3 Testing
- [ ] Questions are displayed with colors
- [ ] Question types are clearly indicated
- [ ] Answer input has helpful instructions
- [ ] Error messages are formatted nicely
- [ ] Overall UX is visually appealing

### Phase 4 Testing
- [ ] Debug mode can be enabled via env var
- [ ] AI calls are logged to correct file
- [ ] Log format is valid JSONL
- [ ] Logs include all required fields
- [ ] No logs created when debug mode is off

---

## üìä Effort Estimates

| Phase | Tasks | Estimated Time | Priority |
|-------|-------|---------------|----------|
| Phase 1 | 2 | 3 hours | URGENT |
| Phase 2 | 3 | 6 hours | HIGH |
| Phase 3 | 3 | 8 hours | MEDIUM |
| Phase 4 | 2 | 8 hours | MEDIUM |

**Total Estimated Time**: ~25 hours (~3-4 days)

---

## üöÄ Recommended Execution Order

1. **Day 1**: Phase 1 (Fix blocker + enforce length limits) + Phase 2 (Add progress indicators)
2. **Day 2**: Phase 3 (Improve UX)
3. **Day 3**: Phase 4 (Add logging)

---

## üìù Notes

- **Phase 1 is critical** - blocks normal workflow and produces overly verbose files
- **Length enforcement** is important for keeping files maintainable
- Phase 2 and 3 provide the biggest UX improvement for minimal effort
- Phase 4 is helpful for debugging but not user-facing
- Phase 5 (session recovery) is deferred as nice-to-have

---

**Next Actions**:
1. ‚úì Review this plan
2. Start with Phase 1: Remove placeholder file creation from init
3. Update generate-arch prompts to enforce 125-line limit
4. Add progress indicators (Phase 2)
5. Enhance terminal formatting (Phase 3)

---

## üî• ADDITIONAL CRITICAL ISSUES (2026-01-02 Update)

After user testing, **3 more critical issues** were identified:

### **Issue #8: No AI Context/Token Usage Display** üî¥ **HIGH**
**Problem**: Users have no visibility into:
- How many tokens consumed vs remaining
- Current API call cost
- Budget tracking
- Progress through available context

**Current State**:
- `CostTracker` class exists (`packages/core/src/llm/cost-tracker.ts`)
- Tracks tokens, costs, models, budgets
- **BUT NEVER DISPLAYED TO USER**

**Impact**: Users can't manage API costs or understand usage

---

### **Issue #9: No Streaming Output from AI** üî¥ **CRITICAL**
**Problem**: All AI responses wait for completion before displaying:
- PRD creation: 30-60 second wait with no feedback
- Task generation: 60-120 second wait, appears frozen
- Users expect streaming like ChatGPT/Claude Desktop

**Current State**:
- `LLMProvider` interface (packages/core/src/llm/base.ts:56-59)
- Only supports `generate()` ‚Üí complete response
- No `stream()` method or streaming interface

**Impact**: Worst UX issue - users think command has crashed

---

### **Issue #10: Task Generation Creates Too Many Small Tasks** üü° **MEDIUM**
**Problem**: Simple sudoku website generated:
- 4 features
- 8 stories
- 17 tasks

**Root Cause**:
- Template says "MINIMAL tasks (fewer, larger > many small)" (task-generator.md:70)
- But AI prompts in generate.ts:674-754 don't enforce this
- Contradiction: Template says "30-60 min meaningful units", prompts say "1-4 hours atomic"

**Impact**: Too much overhead - each task requires setup, commit, validation cycles

---

### **Issue #11: tasks-progress.json Redundancy?** ‚úÖ **NOT AN ISSUE**

**User Question**: Is tasks-progress.json redundant with individual task files?

**Analysis**:
```
Data Structure:
‚îú‚îÄ‚îÄ project-index.json (features list only)
‚îú‚îÄ‚îÄ tasks-progress.json (full hierarchy, task refs only)
‚îú‚îÄ‚îÄ F*/F*.json (feature file with stories/task refs)
‚îî‚îÄ‚îÄ F*/S*/T*.json (individual task details)
```

**Purpose of Separation**:
- `tasks-progress.json`: Fast overview, status tracking, hierarchy navigation
- Individual task files: Full details loaded on-demand

**Conclusion**: ‚úÖ **This is good architecture** - NOT redundant
- Allows fast status checks without loading all task files
- Individual files keep detailed context separate
- **No changes needed**

---

## üìÖ Phase 6: AI Context & Token Tracking (NEW - Priority: HIGH)

Display real-time token usage and cost information during AI operations.

### Task 6.1: Add Token Usage Display Utility
**Estimated Effort**: Small
**Files to Create/Modify**:
- `packages/core/src/lib/usage-display.ts` (new)
- `packages/core/src/commands/base.ts`

**Implementation**:

```typescript
// File: packages/core/src/lib/usage-display.ts
import chalk from 'chalk';
import type { CostTracker } from '../llm/cost-tracker.js';

export class UsageDisplay {
  /**
   * Display token usage after AI call
   */
  static displayUsage(costTracker: CostTracker, verbose: boolean = false): void {
    const summary = costTracker.getSummary();
    console.log(chalk.cyan(`\nüí∞ ${summary}`));

    if (verbose) {
      const report = costTracker.getReport(true);
      console.log(chalk.dim(report));
    }
  }

  /**
   * Display usage summary inline (one line)
   */
  static displayInlineSummary(
    promptTokens: number,
    completionTokens: number,
    cost: number
  ): void {
    const totalTokens = promptTokens + completionTokens;
    console.log(
      chalk.dim(
        `   Tokens: ${promptTokens.toLocaleString()} prompt + ${completionTokens.toLocaleString()} completion = ${totalTokens.toLocaleString()} total | Cost: $${cost.toFixed(4)}`
      )
    );
  }

  /**
   * Display progress with token estimate
   */
  static displayEstimate(promptTokens: number, estimatedCost: number): void {
    console.log(
      chalk.dim(
        `   Estimated: ~${promptTokens.toLocaleString()} prompt tokens | ~$${estimatedCost.toFixed(4)}`
      )
    );
  }

  /**
   * Display budget warning
   */
  static displayBudgetWarning(used: number, limit: number): void {
    const percentage = (used / limit) * 100;
    const color = percentage >= 90 ? chalk.red : percentage >= 75 ? chalk.yellow : chalk.green;

    console.log(
      color(`   Budget: $${used.toFixed(4)} / $${limit.toFixed(2)} (${percentage.toFixed(1)}%)`)
    );
  }
}
```

### Task 6.2: Integrate Usage Display with Commands
**Estimated Effort**: Medium
**Files to Modify**:
- `packages/core/src/commands/prd/create.ts`
- `packages/core/src/commands/prd/generate-arch.ts`
- `packages/core/src/commands/tasks/generate.ts`

**Example Integration**:

```typescript
// File: packages/core/src/commands/prd/create.ts

import { UsageDisplay } from '../../lib/usage-display.js';

private async generateQuestions(title: string, summary: string): Promise<Question[]> {
  const progress = new ProgressIndicator();
  progress.start('Analyzing requirements and generating questions...');

  const response = await this.llmProvider?.generate(...);

  if (response) {
    progress.succeed('Questions generated');

    // Display token usage
    if (response.promptTokens && response.completionTokens) {
      const cost = this.costTracker.calculateCost(
        response.model,
        response.promptTokens,
        response.completionTokens
      );
      UsageDisplay.displayInlineSummary(
        response.promptTokens,
        response.completionTokens,
        cost
      );
    }
  }

  return this.parseAllQuestions(response.content);
}
```

### Task 6.3: Add Session Summary on Command Completion
**Estimated Effort**: Small
**Files to Modify**:
- `packages/core/src/commands/base.ts`

**Implementation**:

```typescript
// File: packages/core/src/commands/base.ts

protected displaySessionSummary(): void {
  console.log('\n' + '‚îÄ'.repeat(60));
  console.log(chalk.bold.cyan('Session Summary'));
  console.log('‚îÄ'.repeat(60));

  UsageDisplay.displayUsage(this.costTracker, false);

  // Display budget if configured
  const remaining = this.costTracker.getRemainingBudget();
  if (remaining !== null) {
    const total = this.costTracker.getTotalCost();
    const limit = total + remaining;
    UsageDisplay.displayBudgetWarning(total, limit);
  }

  console.log('‚îÄ'.repeat(60));
}

// Call at end of execute() for all LLM-using commands
async execute(...): Promise<CommandResult> {
  // ... existing code ...

  if (this.isLLMAvailable()) {
    this.displaySessionSummary();
  }

  return result;
}
```

---

## üìÖ Phase 7: Streaming AI Responses (NEW - Priority: CRITICAL)

Implement streaming for real-time AI response display.

### Task 7.1: Extend LLM Provider Interface for Streaming
**Estimated Effort**: Large
**Files to Modify**:
- `packages/core/src/llm/base.ts`
- `packages/core/src/llm/providers/anthropic.ts`
- `packages/core/src/llm/providers/openai-compatible.ts`
- `packages/core/src/llm/providers/ollama.ts`

**Implementation**:

```typescript
// File: packages/core/src/llm/base.ts

export interface LLMStreamChunk {
  delta: string; // Incremental content
  isComplete: boolean;
  model?: string;
  tokensUsed?: number;
  promptTokens?: number;
  completionTokens?: number;
}

export type StreamCallback = (chunk: LLMStreamChunk) => void;

export abstract class LLMProvider {
  // ... existing code ...

  /**
   * Generate text from the LLM (blocking)
   */
  abstract generate(
    messages: LLMMessage[],
    options?: LLMGenerationOptions,
  ): Promise<LLMGenerationResult>;

  /**
   * Generate text from the LLM with streaming (NEW)
   * Override this in providers that support streaming
   */
  async generateStream(
    messages: LLMMessage[],
    options: LLMGenerationOptions | undefined,
    onChunk: StreamCallback,
  ): Promise<LLMGenerationResult> {
    // Default implementation: fall back to non-streaming
    const result = await this.generate(messages, options);

    // Simulate streaming by sending complete result at once
    onChunk({
      delta: result.content,
      isComplete: true,
      model: result.model,
      tokensUsed: result.tokensUsed,
      promptTokens: result.promptTokens,
      completionTokens: result.completionTokens,
    });

    return result;
  }

  /**
   * Check if provider supports streaming
   */
  supportsStreaming(): boolean {
    return false; // Override in providers that support it
  }
}
```

### Task 7.2: Implement Streaming in Anthropic Provider
**Estimated Effort**: Medium
**Files to Modify**:
- `packages/core/src/llm/providers/anthropic.ts`

**Implementation**:

```typescript
// File: packages/core/src/llm/providers/anthropic.ts

import Anthropic from '@anthropic-ai/sdk';

export class AnthropicProvider extends LLMProvider {
  // ... existing code ...

  override supportsStreaming(): boolean {
    return true;
  }

  override async generateStream(
    messages: LLMMessage[],
    options: LLMGenerationOptions = {},
    onChunk: StreamCallback,
  ): Promise<LLMGenerationResult> {
    const stream = await this.client.messages.stream({
      model: this.model,
      max_tokens: options.maxTokens ?? 4096,
      temperature: options.temperature ?? 0.7,
      messages: messages.map(m => ({
        role: m.role === 'system' ? 'user' : m.role, // Anthropic handles system differently
        content: m.content,
      })),
    });

    let fullContent = '';
    let promptTokens = 0;
    let completionTokens = 0;

    for await (const chunk of stream) {
      if (chunk.type === 'content_block_delta' && chunk.delta.type === 'text_delta') {
        const delta = chunk.delta.text;
        fullContent += delta;

        onChunk({
          delta,
          isComplete: false,
        });
      } else if (chunk.type === 'message_stop') {
        // Get final token counts
        const usage = await stream.finalMessage();
        promptTokens = usage.usage.input_tokens;
        completionTokens = usage.usage.output_tokens;

        onChunk({
          delta: '',
          isComplete: true,
          model: this.model,
          promptTokens,
          completionTokens,
          tokensUsed: promptTokens + completionTokens,
        });
      }
    }

    return {
      content: fullContent,
      model: this.model,
      tokensUsed: promptTokens + completionTokens,
      promptTokens,
      completionTokens,
      finishReason: 'end_turn',
    };
  }
}
```

### Task 7.3: Add Stream Display Utility
**Estimated Effort**: Medium
**Files to Create**:
- `packages/core/src/lib/stream-display.ts` (new)

**Implementation**:

```typescript
// File: packages/core/src/lib/stream-display.ts
import chalk from 'chalk';
import type { LLMStreamChunk } from '../llm/base.js';

export class StreamDisplay {
  private contentBuffer: string = '';
  private isFirstChunk: boolean = true;

  constructor(private label?: string) {}

  /**
   * Handle stream chunk and display it
   */
  handleChunk(chunk: LLMStreamChunk): void {
    if (this.isFirstChunk && this.label) {
      console.log(chalk.cyan(`\n${this.label}:`));
      console.log(chalk.dim('‚îÄ'.repeat(60)));
      this.isFirstChunk = false;
    }

    if (chunk.delta) {
      // Write chunk without newline (stream effect)
      process.stdout.write(chunk.delta);
      this.contentBuffer += chunk.delta;
    }

    if (chunk.isComplete) {
      // Add final newline
      console.log('');
      console.log(chalk.dim('‚îÄ'.repeat(60)));

      // Display token usage if available
      if (chunk.promptTokens && chunk.completionTokens) {
        console.log(
          chalk.dim(
            `Tokens: ${chunk.promptTokens} prompt + ${chunk.completionTokens} completion = ${chunk.tokensUsed} total`
          )
        );
      }
    }
  }

  /**
   * Get accumulated content
   */
  getContent(): string {
    return this.contentBuffer;
  }

  /**
   * Reset display
   */
  reset(): void {
    this.contentBuffer = '';
    this.isFirstChunk = true;
  }
}
```

### Task 7.4: Integrate Streaming in Commands
**Estimated Effort**: Large
**Files to Modify**:
- `packages/core/src/commands/prd/create.ts`
- `packages/core/src/commands/prd/generate-arch.ts`
- `packages/core/src/commands/tasks/generate.ts`

**Example Integration**:

```typescript
// File: packages/core/src/commands/prd/create.ts

import { StreamDisplay } from '../../lib/stream-display.js';

private async generateQuestions(title: string, summary: string): Promise<Question[]> {
  const systemPrompt = this.buildSystemPromptForQuestions();
  const userPrompt = this.buildQuestionPrompt(title, summary);

  const messages = [
    { role: "system" as const, content: systemPrompt },
    { role: "user" as const, content: userPrompt },
  ];

  const options = {
    maxTokens: 2000,
    temperature: 0.7,
  };

  // Use streaming if supported
  if (this.llmProvider?.supportsStreaming()) {
    const streamDisplay = new StreamDisplay('Generating questions');

    const response = await this.llmProvider.generateStream(
      messages,
      options,
      (chunk) => streamDisplay.handleChunk(chunk)
    );

    // Track cost
    this.costTracker.trackUsage(response);

    return this.parseAllQuestions(response.content);
  } else {
    // Fallback to non-streaming with progress indicator
    const progress = new ProgressIndicator();
    progress.start('Analyzing requirements and generating questions...');

    const response = await this.llmProvider?.generate(messages, options);

    if (!response) {
      progress.fail('Failed to generate questions');
      return [];
    }

    progress.succeed('Questions generated');
    this.costTracker.trackUsage(response);

    return this.parseAllQuestions(response.content);
  }
}
```

---

## üìÖ Phase 8: Optimize Task Generation Granularity (NEW - Priority: MEDIUM)

Fix task generation to create fewer, larger, more meaningful tasks.

### Task 8.1: Update Task Generation System Prompt
**Estimated Effort**: Small
**Files to Modify**:
- `packages/core/src/commands/tasks/generate.ts:674-731`

**Problem**: Current prompt says "1-4 hours atomic tasks" which leads to too many small tasks.

**Solution**: Update to emphasize fewer, larger tasks:

```typescript
// File: packages/core/src/commands/tasks/generate.ts

const systemPrompt = `You are an expert software architect and project planner.

Your mission is to analyze a PRD and break it down into a structured, executable task hierarchy.

CRITICAL RULES FOR TASK GRANULARITY:
1. CREATE FEWER, LARGER TASKS (not many small ones)
2. Each task should be a MEANINGFUL UNIT (30-90 minutes of work)
3. Tasks should touch MULTIPLE files and implement a complete sub-feature
4. AVOID creating separate tasks for simple steps like "create file", "add validation"
5. COMBINE related steps into single tasks (e.g., "Implement user persistence" includes migration + model + repository + service)

BAD (too granular):
  - Task 1.1.0: Create migration file
  - Task 1.1.1: Create User model
  - Task 1.1.2: Add validation to User model
  - Task 1.1.3: Create repository
  - Task 1.1.4: Add tests

GOOD (proper granularity):
  - Task 1.1.0: Implement user persistence layer (includes migration, model, validation, repository, tests)

TARGET:
- Simple features: 2-4 tasks total
- Medium features: 5-8 tasks total
- Complex features: 10-15 tasks total

For a "Simple Sudoku Website" you should create approximately:
- 1-2 features (e.g., "Game UI", "Game Logic")
- 2-3 stories per feature (e.g., "Initial board display", "User input", "Solution validation")
- 1-3 tasks per story
- TOTAL: ~6-10 tasks maximum

Each task must:
- Be independently testable
- Implement a complete sub-feature
- Have clear acceptance criteria
- Include multiple related files/changes

Available skills: backend, frontend, fullstack, devops, docs, mobile

Output ONLY valid JSON in this exact structure:
{
  "project": "project-name",
  "features": [
    {
      "id": "1",
      "title": "Feature name",
      "description": "Feature description",
      "status": "not-started",
      "stories": [
        {
          "id": "1.1",
          "title": "Story name",
          "description": "Story description",
          "status": "not-started",
          "tasks": [
            {
              "id": "1.1.0",
              "title": "Task title (broad, meaningful unit)",
              "description": "Detailed task description covering all steps",
              "skill": "backend",
              "status": "not-started",
              "estimatedHours": 1.5,
              "dependencies": [],
              "context": ["path/to/file.ts - Description"],
              "subtasks": [
                {
                  "id": "1",
                  "description": "Subtask 1",
                  "status": "not-started"
                },
                {
                  "id": "2",
                  "description": "Subtask 2",
                  "status": "not-started"
                }
              ],
              "acceptanceCriteria": ["Criterion 1", "Criterion 2"]
            }
          ]
        }
      ]
    }
  ]
}`;
```

### Task 8.2: Update task-generator.md Template
**Estimated Effort**: Small
**Files to Modify**:
- `packages/core/templates/protocols/task-generator.md`

**Changes**:
1. Make "MINIMAL tasks" guidance more prominent
2. Add explicit examples of bad vs good granularity
3. Add target task counts for different project sizes

```markdown
## Task Granularity

**CRITICAL PRINCIPLE: FEWER, LARGER TASKS**

Optimize for MINIMAL number of tasks. Each task should be a meaningful unit (30-90 min) that implements a complete sub-feature across multiple files.

### Target Task Counts

| Project Complexity | Total Tasks |
|-------------------|-------------|
| Simple (Sudoku game, calculator) | 6-10 tasks |
| Medium (Todo app, blog) | 15-25 tasks |
| Large (E-commerce, CRM) | 30-50 tasks |

### Anti-Patterns (DON'T DO THIS)

‚ùå One task per file:
- Task 1.1.0: Create migration
- Task 1.1.1: Create model
- Task 1.1.2: Create repository
- Task 1.1.3: Add tests

‚ùå Separating simple steps:
- Task 2.1.0: Add input field
- Task 2.1.1: Add validation
- Task 2.1.2: Style input

### Good Patterns (DO THIS)

‚úÖ Complete sub-feature:
- Task 1.1.0: Implement user persistence (migration + model + repository + tests)

‚úÖ Meaningful UI component:
- Task 2.1.0: Implement validated user input form (fields + validation + styling + error handling)

### Rule of Thumb

Before creating a task, ask:
1. Can this be combined with adjacent tasks? ‚Üí If yes, combine them
2. Does this touch <3 files? ‚Üí Probably too small, combine it
3. Is this a single-line change? ‚Üí Definitely combine it
4. Will this take <20 minutes? ‚Üí Combine it

Good task size: 30-90 minutes, touches 3-10 files, implements a complete sub-feature.
```

---

## üéØ Updated Success Criteria

### Phase 6 Success (Token Tracking)
- [ ] Token usage displayed after each AI call
- [ ] Session summary shown at end of command
- [ ] Budget warnings display when threshold exceeded
- [ ] Cost breakdown is accurate and helpful

### Phase 7 Success (Streaming)
- [ ] Streaming works for Anthropic provider
- [ ] Streaming works for OpenAI-compatible provider
- [ ] Fallback to non-streaming for providers that don't support it
- [ ] Token counts display after stream completes
- [ ] No "frozen terminal" - users see progress in real-time

### Phase 8 Success (Task Granularity)
- [ ] Simple projects generate 6-10 tasks (not 17+)
- [ ] Tasks are meaningful units (30-90 min, multiple files)
- [ ] No micro-tasks like "create migration" or "add validation"
- [ ] Sudoku website example generates ~6-10 tasks total
- [ ] Template clearly discourages over-granularity

---

## üì¶ Updated Dependencies

```bash
# Phase 2
pnpm add ora

# Phase 3 & 6 & 7
pnpm add chalk

# Phase 7 (if not already installed)
pnpm add @anthropic-ai/sdk
```

---

## üìä Updated Effort Estimates

| Phase | Tasks | Estimated Time | Priority |
|-------|-------|---------------|----------|
| Phase 1 | 2 | 3 hours | URGENT |
| Phase 2 | 3 | 6 hours | HIGH |
| Phase 3 | 3 | 8 hours | MEDIUM |
| Phase 4 | 2 | 8 hours | MEDIUM |
| **Phase 6** | **3** | **6 hours** | **HIGH** |
| **Phase 7** | **4** | **16 hours** | **CRITICAL** |
| **Phase 8** | **2** | **3 hours** | **MEDIUM** |

**Total Estimated Time**: ~50 hours (~6-7 days)

---

## üöÄ Updated Execution Order

### Week 1 (Critical Path)
1. **Day 1-2**: Phase 1 (blocker fix) + Phase 6 (token tracking) + Phase 8 (task granularity)
2. **Day 3-5**: Phase 7 (streaming) - most complex but highest impact
3. **Day 6**: Phase 2 (progress indicators) - quick win if streaming not done

### Week 2 (Polish)
4. **Day 7**: Phase 3 (enhanced UX)
5. **Day 8**: Phase 4 (logging)

---

## üìù Updated Notes

- **Phase 7 (Streaming) is now the highest priority** - worst UX issue
- **Phase 6 (Token Tracking) is quick win** - CostTracker already exists, just display it
- **Phase 8 (Task Granularity) is critical** - affects all future task generation
- **tasks-progress.json is NOT redundant** - good architecture, no changes needed
- Streaming requires provider-specific implementation (Anthropic, OpenAI, Ollama)
- Fallback to non-streaming must be seamless for providers that don't support it

---

**Priority Order (Revised)**:
1. üî¥ **Phase 9**: Interactive tech stack selection (CRITICAL - blocks meaningful arch generation)
2. üî¥ **Phase 7**: Streaming (biggest UX impact)
3. üî¥ **Phase 1**: Fix blocker + length limits
4. üü° **Phase 6**: Token tracking (quick win)
5. üü° **Phase 8**: Task granularity (affects all future work)
6. üü¢ **Phase 2**: Progress indicators (if streaming not ready)
7. üü¢ **Phase 3**: Enhanced UX
8. üü¢ **Phase 4**: Logging

---

## üî• CRITICAL DESIGN FLAW: Tech Stack Unknown (2026-01-02 Update #2)

### **Issue #12: Cannot Generate Meaningful Architecture Without Tech Stack** üî¥ **CRITICAL**

**Fundamental Problem**:
```
Current Flow (BROKEN):
1. User creates PRD (describes WHAT to build)
2. User runs generate-arch (reads PRD)
3. ‚ùå AI doesn't know tech stack
4. ‚ùå AI guesses or hallucinates generic rules
5. Result: Useless, generic architecture rules
```

**Example**:
- PRD: "Build a todo app"
- AI doesn't know: React? Vue? Svelte? Node? Python? PostgreSQL? MongoDB?
- Result: Generic nonsense like "follow best practices"

**Root Cause**: PRDs describe requirements, NOT technology choices

---

## üìÖ Phase 9: Interactive Tech Stack Selection (NEW - Priority: CRITICAL)

Make `generate-arch` interactive with tech stack detection, selection, and web search for best practices.

### **New Flow Overview**

```
1. Read PRD ‚úì
2. Detect existing tech stack (brownfield) OR
   Suggest tech stack options (greenfield)
3. User selects/confirms stack
4. Web search for current best practices (2026)
5. Generate tech-stack.md (NEW FILE)
6. Generate architecture-rules.md (targeted to stack)
7. Generate coding-standards.md (targeted to stack)
```

---

### Task 9.1: Add Tech Stack Detection
**Estimated Effort**: Medium
**Files to Create/Modify**:
- `packages/core/src/lib/tech-stack-detector.ts` (new)
- `packages/core/src/commands/prd/generate-arch.ts`

**Implementation**:

```typescript
// File: packages/core/src/lib/tech-stack-detector.ts

import fs from 'node:fs';
import path from 'node:path';

export interface DetectedTech {
  category: 'frontend' | 'backend' | 'database' | 'devops' | 'language';
  name: string;
  version?: string;
  confidence: 'high' | 'medium' | 'low';
  evidence: string; // e.g., "Found package.json with 'react': '18.2.0'"
}

export interface TechStack {
  frontend?: DetectedTech[];
  backend?: DetectedTech[];
  database?: DetectedTech[];
  language?: DetectedTech[];
  devops?: DetectedTech[];
}

export class TechStackDetector {
  constructor(private projectRoot: string) {}

  /**
   * Detect tech stack from existing codebase
   */
  async detect(): Promise<TechStack> {
    const stack: TechStack = {};

    // Check package.json
    const packageJsonPath = path.join(this.projectRoot, 'package.json');
    if (fs.existsSync(packageJsonPath)) {
      const packageJson = JSON.parse(fs.readFileSync(packageJsonPath, 'utf-8'));
      const deps = { ...packageJson.dependencies, ...packageJson.devDependencies };

      stack.frontend = this.detectFrontend(deps);
      stack.backend = this.detectBackend(deps);
      stack.database = this.detectDatabase(deps);
    }

    // Check for language-specific files
    stack.language = this.detectLanguage();

    // Check for config files
    stack.devops = this.detectDevOps();

    return stack;
  }

  private detectFrontend(deps: Record<string, string>): DetectedTech[] {
    const detected: DetectedTech[] = [];

    // React
    if (deps['react']) {
      detected.push({
        category: 'frontend',
        name: 'React',
        version: deps['react'],
        confidence: 'high',
        evidence: `package.json contains 'react': '${deps['react']}'`,
      });

      // Next.js
      if (deps['next']) {
        detected.push({
          category: 'frontend',
          name: 'Next.js',
          version: deps['next'],
          confidence: 'high',
          evidence: `package.json contains 'next': '${deps['next']}'`,
        });
      }
    }

    // Vue
    if (deps['vue']) {
      detected.push({
        category: 'frontend',
        name: 'Vue',
        version: deps['vue'],
        confidence: 'high',
        evidence: `package.json contains 'vue': '${deps['vue']}'`,
      });
    }

    // Svelte
    if (deps['svelte']) {
      detected.push({
        category: 'frontend',
        name: 'Svelte',
        version: deps['svelte'],
        confidence: 'high',
        evidence: `package.json contains 'svelte': '${deps['svelte']}'`,
      });
    }

    // Styling
    if (deps['tailwindcss']) {
      detected.push({
        category: 'frontend',
        name: 'Tailwind CSS',
        version: deps['tailwindcss'],
        confidence: 'high',
        evidence: `package.json contains 'tailwindcss': '${deps['tailwindcss']}'`,
      });
    }

    return detected;
  }

  private detectBackend(deps: Record<string, string>): DetectedTech[] {
    const detected: DetectedTech[] = [];

    // Express
    if (deps['express']) {
      detected.push({
        category: 'backend',
        name: 'Express',
        version: deps['express'],
        confidence: 'high',
        evidence: `package.json contains 'express': '${deps['express']}'`,
      });
    }

    // Fastify
    if (deps['fastify']) {
      detected.push({
        category: 'backend',
        name: 'Fastify',
        version: deps['fastify'],
        confidence: 'high',
        evidence: `package.json contains 'fastify': '${deps['fastify']}'`,
      });
    }

    // NestJS
    if (deps['@nestjs/core']) {
      detected.push({
        category: 'backend',
        name: 'NestJS',
        version: deps['@nestjs/core'],
        confidence: 'high',
        evidence: `package.json contains '@nestjs/core'`,
      });
    }

    return detected;
  }

  private detectDatabase(deps: Record<string, string>): DetectedTech[] {
    const detected: DetectedTech[] = [];

    // Prisma
    if (deps['@prisma/client'] || deps['prisma']) {
      detected.push({
        category: 'database',
        name: 'Prisma',
        version: deps['@prisma/client'] || deps['prisma'],
        confidence: 'high',
        evidence: 'Found Prisma in package.json',
      });

      // Try to detect database type from schema.prisma
      const schemaPath = path.join(this.projectRoot, 'prisma', 'schema.prisma');
      if (fs.existsSync(schemaPath)) {
        const schema = fs.readFileSync(schemaPath, 'utf-8');
        if (schema.includes('provider = "postgresql"')) {
          detected.push({
            category: 'database',
            name: 'PostgreSQL',
            confidence: 'high',
            evidence: 'schema.prisma specifies postgresql',
          });
        } else if (schema.includes('provider = "mysql"')) {
          detected.push({
            category: 'database',
            name: 'MySQL',
            confidence: 'high',
            evidence: 'schema.prisma specifies mysql',
          });
        }
      }
    }

    // MongoDB
    if (deps['mongodb'] || deps['mongoose']) {
      detected.push({
        category: 'database',
        name: 'MongoDB',
        version: deps['mongodb'] || deps['mongoose'],
        confidence: 'high',
        evidence: 'Found MongoDB/Mongoose in package.json',
      });
    }

    // Supabase
    if (deps['@supabase/supabase-js']) {
      detected.push({
        category: 'database',
        name: 'Supabase',
        version: deps['@supabase/supabase-js'],
        confidence: 'high',
        evidence: 'Found Supabase client in package.json',
      });
    }

    return detected;
  }

  private detectLanguage(): DetectedTech[] {
    const detected: DetectedTech[] = [];

    // TypeScript
    const tsconfigPath = path.join(this.projectRoot, 'tsconfig.json');
    if (fs.existsSync(tsconfigPath)) {
      const tsconfig = JSON.parse(fs.readFileSync(tsconfigPath, 'utf-8'));
      detected.push({
        category: 'language',
        name: 'TypeScript',
        version: tsconfig.compilerOptions?.target || 'unknown',
        confidence: 'high',
        evidence: 'Found tsconfig.json',
      });
    }

    return detected;
  }

  private detectDevOps(): DetectedTech[] {
    const detected: DetectedTech[] = [];

    // Docker
    const dockerfilePath = path.join(this.projectRoot, 'Dockerfile');
    if (fs.existsSync(dockerfilePath)) {
      detected.push({
        category: 'devops',
        name: 'Docker',
        confidence: 'high',
        evidence: 'Found Dockerfile',
      });
    }

    // Vercel
    const vercelPath = path.join(this.projectRoot, 'vercel.json');
    if (fs.existsSync(vercelPath)) {
      detected.push({
        category: 'devops',
        name: 'Vercel',
        confidence: 'high',
        evidence: 'Found vercel.json',
      });
    }

    return detected;
  }

  /**
   * Format detected stack for display
   */
  formatStack(stack: TechStack): string[] {
    const lines: string[] = [];

    if (stack.language && stack.language.length > 0) {
      lines.push('Language:');
      for (const tech of stack.language) {
        lines.push(`  ‚Ä¢ ${tech.name}${tech.version ? ` ${tech.version}` : ''}`);
      }
    }

    if (stack.frontend && stack.frontend.length > 0) {
      lines.push('\nFrontend:');
      for (const tech of stack.frontend) {
        lines.push(`  ‚Ä¢ ${tech.name}${tech.version ? ` ${tech.version}` : ''}`);
      }
    }

    if (stack.backend && stack.backend.length > 0) {
      lines.push('\nBackend:');
      for (const tech of stack.backend) {
        lines.push(`  ‚Ä¢ ${tech.name}${tech.version ? ` ${tech.version}` : ''}`);
      }
    }

    if (stack.database && stack.database.length > 0) {
      lines.push('\nDatabase:');
      for (const tech of stack.database) {
        lines.push(`  ‚Ä¢ ${tech.name}${tech.version ? ` ${tech.version}` : ''}`);
      }
    }

    if (stack.devops && stack.devops.length > 0) {
      lines.push('\nDevOps:');
      for (const tech of stack.devops) {
        lines.push(`  ‚Ä¢ ${tech.name}${tech.version ? ` ${tech.version}` : ''}`);
      }
    }

    return lines;
  }

  /**
   * Check if codebase appears to be greenfield (new project)
   */
  isGreenfield(): boolean {
    // Check if there are any source files
    const srcDir = path.join(this.projectRoot, 'src');
    const hasSourceFiles = fs.existsSync(srcDir) && fs.readdirSync(srcDir).length > 0;

    // Check if package.json has dependencies
    const packageJsonPath = path.join(this.projectRoot, 'package.json');
    let hasDependencies = false;
    if (fs.existsSync(packageJsonPath)) {
      const packageJson = JSON.parse(fs.readFileSync(packageJsonPath, 'utf-8'));
      const deps = { ...packageJson.dependencies, ...packageJson.devDependencies };
      hasDependencies = Object.keys(deps).length > 5; // More than basic setup
    }

    return !hasSourceFiles && !hasDependencies;
  }
}
```

---

### Task 9.2: Add Tech Stack Suggestion Engine
**Estimated Effort**: Large
**Files to Create**:
- `packages/core/src/lib/tech-stack-suggester.ts` (new)

**Implementation**:

```typescript
// File: packages/core/src/lib/tech-stack-suggester.ts

import type { LLMProvider } from '../llm/base.js';

export interface TechStackOption {
  id: string;
  name: string;
  description: string;
  technologies: {
    frontend?: string[];
    backend?: string[];
    database?: string[];
    devops?: string[];
  };
  pros: string[];
  cons: string[];
  bestFor: string[];
  recommended?: boolean;
}

export class TechStackSuggester {
  constructor(
    private llmProvider: LLMProvider,
    private webSearchEnabled: boolean = true,
  ) {}

  /**
   * Suggest tech stack options based on PRD analysis
   */
  async suggest(prdContent: string): Promise<TechStackOption[]> {
    const systemPrompt = `You are a senior software architect specializing in technology selection.

Your task is to analyze a PRD and suggest 3-4 appropriate tech stack options.

CRITICAL RULES:
1. Suggest CURRENT technologies (2026, not outdated stacks)
2. Match stack to PRD requirements (e.g., real-time ‚Üí WebSockets)
3. Provide specific versions where relevant
4. Mark ONE option as recommended
5. Keep descriptions concise (1-2 sentences)
6. Focus on proven, production-ready technologies

Output ONLY valid JSON in this format:
{
  "options": [
    {
      "id": "1",
      "name": "Next.js + Supabase",
      "description": "Modern fullstack with built-in backend",
      "technologies": {
        "frontend": ["Next.js 14", "React 18", "TypeScript", "Tailwind CSS"],
        "backend": ["Next.js API Routes", "Supabase"],
        "database": ["PostgreSQL (via Supabase)"]
      },
      "pros": [
        "Fast development (BaaS)",
        "Built-in auth and real-time",
        "Great DX"
      ],
      "cons": [
        "Some vendor lock-in",
        "Less control over backend"
      ],
      "bestFor": [
        "MVPs",
        "Rapid prototyping",
        "Small-medium apps"
      ],
      "recommended": true
    }
  ]
}`;

    const userPrompt = `Analyze this PRD and suggest 3-4 tech stack options:

${prdContent}

Consider:
- Project complexity
- Performance requirements
- Real-time needs
- Authentication needs
- Scalability requirements
- Team size/skill level (if mentioned)

Suggest options from simple ‚Üí complex.`;

    const response = await this.llmProvider.generate(
      [
        { role: 'system', content: systemPrompt },
        { role: 'user', content: userPrompt },
      ],
      {
        maxTokens: 3000,
        temperature: 0.3,
      },
    );

    // Parse JSON response
    let jsonContent = response.content.trim();
    if (jsonContent.startsWith('```')) {
      jsonContent = jsonContent
        .replace(/```json\n?/g, '')
        .replace(/```\n?/g, '');
    }

    const parsed = JSON.parse(jsonContent);
    return parsed.options as TechStackOption[];
  }

  /**
   * Enhance suggestions with web search (current best practices)
   */
  async enhanceWithWebSearch(options: TechStackOption[]): Promise<TechStackOption[]> {
    if (!this.webSearchEnabled) {
      return options;
    }

    // TODO: Implement web search integration
    // For each option, search for:
    // - "[Tech] best practices 2026"
    // - "[Tech] architecture patterns 2026"
    // - "[Tech] vs alternatives"

    return options;
  }
}
```

---

### Task 9.3: Create tech-stack.md Generator
**Estimated Effort**: Medium
**Files to Create**:
- `packages/core/src/lib/tech-stack-generator.ts` (new)

**Implementation**:

```typescript
// File: packages/core/src/lib/tech-stack-generator.ts

import type { TechStack } from './tech-stack-detector.js';
import type { TechStackOption } from './tech-stack-suggester.js';
import type { LLMProvider } from '../llm/base.js';

export class TechStackGenerator {
  constructor(private llmProvider: LLMProvider) {}

  /**
   * Generate tech-stack.md from selected option
   */
  async generate(
    selectedOption: TechStackOption,
    prdContent: string,
  ): Promise<string> {
    const systemPrompt = `You are a technical documentation specialist.

Generate a concise tech-stack.md file (MAX 125 lines) that documents:
1. All technologies in the stack (with versions)
2. Key architectural decisions
3. Rationale for each choice (tied to PRD requirements)
4. References to official docs

Format:
# Tech Stack Summary

**Project**: [Project name]
**Created**: [Date]

## Frontend
- **Framework**: [Name + version]
- **UI**: [Libraries]
...

## Backend
...

## Key Decisions

### 1. [Decision]
**Decision**: [What]
**Reason**: [Why - tied to PRD requirement]
**Trade-off**: [Cons]

## References
- [Official docs links]

CRITICAL: Keep under 125 lines, be specific, no fluff.`;

    const userPrompt = `Generate tech-stack.md for:

SELECTED STACK:
${JSON.stringify(selectedOption, null, 2)}

PRD:
${prdContent}

Include:
- Specific versions
- WHY each tech was chosen (link to PRD requirements)
- Trade-offs made
- Key dependencies list`;

    const response = await this.llmProvider.generate(
      [
        { role: 'system', content: systemPrompt },
        { role: 'user', content: userPrompt },
      ],
      {
        maxTokens: 2000,
        temperature: 0.3,
      },
    );

    return response.content;
  }
}
```

---

### Task 9.4: Make generate-arch Interactive
**Estimated Effort**: Large
**Files to Modify**:
- `packages/core/src/commands/prd/generate-arch.ts`

**Key Changes**:

```typescript
// File: packages/core/src/commands/prd/generate-arch.ts

import { TechStackDetector } from '../../lib/tech-stack-detector.js';
import { TechStackSuggester } from '../../lib/tech-stack-suggester.js';
import { TechStackGenerator } from '../../lib/tech-stack-generator.js';
import { TerminalFormatter } from '../../lib/terminal-formatter.js';
import readline from 'node:readline';

export class PrdGenerateArchCommand extends BaseCommand {
  async execute(prdFile: string): Promise<CommandResult> {
    // ... existing validation ...

    // Read PRD content
    const prdContent = fs.readFileSync(prdFilePath, 'utf-8');

    // STEP 1: Detect existing tech stack
    console.log(TerminalFormatter.header('TECH STACK DETECTION'));
    console.log('Scanning codebase for existing technologies...\n');

    const detector = new TechStackDetector(this.context.projectRoot);
    const detectedStack = await detector.detect();
    const isGreenfield = detector.isGreenfield();

    if (!isGreenfield && Object.keys(detectedStack).some(k => detectedStack[k]?.length > 0)) {
      // Brownfield: Show detected stack
      console.log('‚úì Detected existing tech stack:\n');
      const formatted = detector.formatStack(detectedStack);
      formatted.forEach(line => console.log(chalk.cyan(line)));

      // Ask for confirmation
      const useDetected = await this.confirm(
        '\nUse detected stack for architecture generation?',
        'yes',
      );

      if (useDetected) {
        // Use detected stack
        return this.generateWithDetectedStack(detectedStack, prdContent, prdFile, paths);
      }
    }

    // STEP 2: Suggest tech stack options (greenfield or user rejected detected)
    console.log('\n' + TerminalFormatter.header('TECH STACK SELECTION'));
    console.log('Analyzing PRD to suggest appropriate tech stacks...\n');

    const suggester = new TechStackSuggester(this.llmProvider);
    const options = await suggester.suggest(prdContent);

    // Display options
    console.log(chalk.bold('RECOMMENDED STACKS:\n'));
    options.forEach((option, i) => {
      const marker = option.recommended ? chalk.green('‚úì RECOMMENDED') : '';
      console.log(chalk.bold(`[${i + 1}] ${option.name} ${marker}`));
      console.log(chalk.dim(`    ${option.description}\n`));

      console.log('    Technologies:');
      if (option.technologies.frontend) {
        console.log(chalk.cyan(`      Frontend: ${option.technologies.frontend.join(', ')}`));
      }
      if (option.technologies.backend) {
        console.log(chalk.cyan(`      Backend: ${option.technologies.backend.join(', ')}`));
      }
      if (option.technologies.database) {
        console.log(chalk.cyan(`      Database: ${option.technologies.database.join(', ')}`));
      }

      console.log('\n    Pros:');
      option.pros.forEach(pro => console.log(chalk.green(`      ‚úì ${pro}`)));

      console.log('\n    Cons:');
      option.cons.forEach(con => console.log(chalk.yellow(`      ‚ö† ${con}`)));

      console.log('\n    Best for:');
      option.bestFor.forEach(use => console.log(chalk.dim(`      ‚Ä¢ ${use}`)));

      console.log('\n' + '‚îÄ'.repeat(60) + '\n');
    });

    // Get user choice
    const selected = await this.promptChoice(
      `Select tech stack [1-${options.length}]:`,
      options.length,
    );

    const selectedOption = options[selected - 1];

    // STEP 3: Generate tech-stack.md
    console.log('\n' + TerminalFormatter.section('GENERATING TECH STACK DOCUMENTATION'));

    const techStackGenerator = new TechStackGenerator(this.llmProvider);
    const techStackContent = await techStackGenerator.generate(selectedOption, prdContent);

    const techStackPath = path.join(paths.refDir, 'tech-stack.md');
    fs.writeFileSync(techStackPath, techStackContent, 'utf-8');

    console.log(chalk.green(`‚úì Generated tech-stack.md (${techStackContent.split('\n').length} lines)`));

    // STEP 4: Generate architecture-rules.md and coding-standards.md
    // (with tech stack context)
    return this.generateArchitectureFiles(
      prdContent,
      techStackContent,
      selectedOption,
      prdFile,
      paths,
    );
  }

  private async promptChoice(question: string, maxChoice: number): Promise<number> {
    const rl = readline.createInterface({
      input: process.stdin,
      output: process.stdout,
    });

    const answer = await new Promise<string>((resolve) => {
      rl.question(chalk.cyan(question) + ' ', (ans) => {
        rl.close();
        resolve(ans.trim());
      });
    });

    const choice = parseInt(answer, 10);
    if (isNaN(choice) || choice < 1 || choice > maxChoice) {
      console.log(chalk.red(`\n‚ö† Invalid choice. Please select 1-${maxChoice}\n`));
      return this.promptChoice(question, maxChoice);
    }

    return choice;
  }

  private async generateArchitectureFiles(
    prdContent: string,
    techStackContent: string,
    selectedOption: TechStackOption,
    prdFile: string,
    paths: ReturnType<ConfigLoader["getPaths"]>,
  ): Promise<CommandResult> {
    // Update system prompts to include tech stack context
    const updatedSystemPrompt = `... existing prompt ...

TECH STACK CONTEXT:
${techStackContent}

Generate rules SPECIFIC to this stack (not generic).`;

    // Continue with existing arch generation...
  }
}
```

---

### Task 9.5: Add Package Version Validator
**Estimated Effort**: Medium (8 hours)
**Files to Create**:
- `packages/core/src/lib/package-validator.ts` (new)

**Purpose**: Validate npm/PyPI packages and get latest stable versions, detect deprecations.

**Key Features**:
```typescript
export class PackageValidator {
  // Query npm registry API
  async validateNpmPackage(packageName: string): Promise<PackageInfo>

  // Query PyPI API
  async validatePyPiPackage(packageName: string): Promise<PackageInfo>

  // Validate multiple packages
  async validatePackages(packages: Array<{name, ecosystem}>): Promise<ValidationResult[]>

  // Check if actively maintained (last publish date)
  isActivelyMaintained(info: PackageInfo): boolean

  // Extract replacement package from deprecation message
  extractReplacementPackage(message?: string): string | undefined
}

export interface PackageInfo {
  name: string;
  latestStableVersion: string;
  isDeprecated: boolean;
  deprecationMessage?: string;
  replacementPackage?: string;
  weeklyDownloads?: number;
  lastPublished?: string;
}
```

**API Endpoints Used**:
- npm registry: `https://registry.npmjs.org/{package}`
- npm stats: `https://api.npmjs.org/downloads/point/last-week/{package}`
- PyPI: `https://pypi.org/pypi/{package}/json`

**Validation Checks**:
1. Package exists and is accessible
2. Latest stable version (exclude beta/alpha/rc)
3. Deprecation status and message
4. Weekly download count (popularity indicator)
5. Last publish date (maintenance indicator)
6. Extract replacement package if deprecated

**Example Output**:
```
Package Validation Results:
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
‚úÖ next
   Latest: 14.1.0
   Last Published: 2024-01-15
   Weekly Downloads: 5,234,567

‚ùå moment
   Latest: 2.29.4
   Last Published: 2022-07-06
   ‚ö†Ô∏è  DEPRECATED: This package is in maintenance mode
   üí° Use date-fns or dayjs instead

‚ö†Ô∏è  request
   Latest: 2.88.2
   ‚ö†Ô∏è  Low usage: Only 234 downloads/week - may not be maintained
```

---

### Task 9.6: Integrate Package Validation into Tech Stack Suggester
**Estimated Effort**: Small (4 hours)
**Files to Modify**:
- `packages/core/src/lib/tech-stack-suggester.ts`

**Purpose**: Automatically validate and update package versions in AI suggestions.

**Implementation Flow**:
```typescript
async suggest(prdContent: string): Promise<TechStackOption[]> {
  // 1. Get AI suggestions (may have outdated versions)
  const aiSuggestions = await this.getAISuggestions(prdContent);

  // 2. Validate packages via npm/PyPI APIs
  console.log('üîç Validating package versions...');
  const validatedOptions = await this.validateOptions(aiSuggestions);

  // 3. Return options with REAL versions
  return validatedOptions;
}

private async validateOptions(options: TechStackOption[]): Promise<TechStackOption[]> {
  for (const option of options) {
    // Extract package names from technologies
    const npmPackages = this.extractPackageNames(option.technologies);

    // Validate each package
    const results = await this.validator.validatePackages(npmPackages);

    // Update option with validated versions
    for (const result of results) {
      if (result.validated.isDeprecated) {
        // Mark option as not recommended
        option.recommended = false;
        option.cons.unshift(`‚ö†Ô∏è  Contains deprecated: ${result.package}`);

        if (result.recommendation) {
          option.cons.push(`üí° ${result.recommendation}`);
        }
      }

      // Update version in technologies array
      option.technologies = this.updateVersions(
        option.technologies,
        result.package,
        result.validated.latestStableVersion
      );
    }
  }

  return options;
}
```

**Output Example**:
```
TECH STACK SELECTION
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

üîç Validating package versions and checking for deprecations...

   ‚úÖ next: 14.1.0
   ‚úÖ react: 18.2.0
   ‚úÖ typescript: 5.3.3
   ‚ùå moment: DEPRECATED
      üí° Use date-fns or dayjs instead

[1] Next.js + Supabase ‚úì RECOMMENDED
    Technologies:
      Frontend: next 14.1.0, react 18.2.0, typescript 5.3.3
      ...
```

---

### Task 9.7: Add Known Package Alternatives Map
**Estimated Effort**: Small (2 hours)
**Files to Create**:
- `packages/core/src/lib/package-alternatives.ts` (new)

**Purpose**: Hardcoded map of deprecated packages and their modern replacements.

**Implementation**:
```typescript
export const PACKAGE_ALTERNATIVES: Record<string, {
  replacement: string;
  reason: string;
  migration?: string;
}> = {
  'request': {
    replacement: 'axios or native fetch',
    reason: 'request was deprecated in 2020',
    migration: 'https://github.com/request/request/issues/3143',
  },
  'moment': {
    replacement: 'date-fns or dayjs',
    reason: 'moment is in maintenance mode',
    migration: 'https://momentjs.com/docs/#/-project-status/',
  },
  'create-react-app': {
    replacement: 'Vite or Next.js',
    reason: 'CRA is slow and no longer recommended',
  },
  '@vue/cli': {
    replacement: 'Vite',
    reason: 'Vue CLI is deprecated, Vite is official tool',
  },
  'enzyme': {
    replacement: '@testing-library/react',
    reason: 'enzyme is no longer maintained for React 18+',
  },
  'styled-components': {
    replacement: 'Tailwind CSS or CSS Modules',
    reason: 'Runtime CSS-in-JS has performance issues',
  },
};

export function getAlternative(packageName: string) {
  return PACKAGE_ALTERNATIVES[packageName.toLowerCase()];
}
```

---

### Task 9.8: Add Web Search for Best Practices (Optional)
**Estimated Effort**: Medium (6 hours)
**Files to Modify**:
- `packages/core/src/lib/tech-stack-suggester.ts`

**Purpose**: Use web search to validate AI suggestions against current industry practices.

**Searches to Perform**:
- "{Tech} best practices 2026"
- "{Tech} architecture patterns 2026"
- "{Tech} vs alternatives 2026"
- "Is {Tech} still maintained 2026"

**Implementation** (stub for future):
```typescript
async enhanceWithWebSearch(options: TechStackOption[]): Promise<TechStackOption[]> {
  if (!this.webSearchEnabled) {
    return options;
  }

  console.log('üåê Searching for current best practices...\n');

  for (const option of options) {
    const mainTech = option.technologies.frontend?.[0] || option.technologies.backend?.[0];
    if (mainTech) {
      const cleanTech = this.cleanPackageName(mainTech);
      const searchQuery = `${cleanTech} best practices 2026`;

      // Use WebSearch tool to find current recommendations
      // Extract insights about whether tech is current/recommended
      // Update pros/cons based on findings
    }
  }

  return options;
}
```

---

### Task 9.9: Add Dependency Compatibility Checker
**Estimated Effort**: Large (12 hours)
**Files to Create**:
- `packages/core/src/lib/dependency-compatibility.ts` (new)

**Purpose**: Validate that selected package versions are compatible with each other (peer dependencies).

**Critical Problem Being Solved**:
```
BROKEN COMBINATION:
{
  "next": "13.5.0",      // Requires React 18.x
  "react": "19.0.0"      // ‚ùå NOT COMPATIBLE!
}

Result: npm install fails with peer dependency conflict
```

**Key Features**:
```typescript
export class DependencyCompatibilityChecker {
  // Check if a set of packages are compatible
  async checkCompatibility(
    packages: Array<{name: string, version: string}>
  ): Promise<CompatibilityResult>

  // Get package metadata including peer dependencies
  async getPackageMetadata(name: string, version: string): Promise<PackageVersion>

  // Check if version satisfies semver range
  satisfiesVersionRange(version: string, range: string): boolean

  // Find compatible version that satisfies peer dependency
  async findCompatibleVersion(packageName: string, versionRange: string): Promise<string | null>

  // Auto-adjust versions to resolve conflicts
  async findCompatibleVersions(): Promise<Map<string, string>>
}

export interface CompatibilityResult {
  compatible: boolean;
  issues: CompatibilityIssue[];
  adjustedVersions?: Map<string, string>;
  compatibilityMatrix?: string[][];
}
```

**Validation Checks**:
1. **Peer Dependencies**: Check package.json `peerDependencies` field
2. **Known Incompatibilities**: Hardcoded rules for common issues
   - Next.js 13 + React 19 (incompatible)
   - Next.js 14 + React 18/19 (compatible)
   - Prisma CLI + @prisma/client (must match exactly)
   - React + React DOM (must match exactly)
   - @types/react + React (major version must match)
   - Tailwind 3.x + PostCSS 8.x (required)
3. **Version Range Matching**: Parse semver ranges (^, ~, >=, *, etc.)
4. **Transitive Dependencies**: Check dependencies of dependencies

**Example Output**:
```
üîó Checking dependency compatibility...

   ‚ùå next@13.5.0 requires react@^18.2.0
      Selected: react@19.0.0
      CONFLICT: React 19 not supported by Next.js 13

   üîß Auto-adjusting versions for compatibility...
      next: 13.5.0 ‚Üí 14.1.0 (supports React 19)

   ‚úÖ All packages are now compatible!

üìä Compatibility Matrix:
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Package         | Version | Requires                | Status
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
next            | 14.1.0  | react: ^18.2.0 or ^19   | ‚úÖ
react           | 19.0.0  | -                       | ‚úÖ
react-dom       | 19.0.0  | react: 19.0.0 (exact)   | ‚úÖ
tailwindcss     | 3.4.1   | postcss: ^8.0.0         | ‚úÖ
```

**Known Incompatibility Rules**:
```typescript
private checkKnownIncompatibilities(packages: Map<string, string>): CompatibilityIssue[] {
  const issues: CompatibilityIssue[] = [];

  // Next.js + React compatibility
  if (next@13.x && react@19.x) {
    issues.push({
      message: 'Next.js 13 requires React 18.x. Upgrade to Next.js 14+ for React 19.',
      severity: 'error'
    });
  }

  // Prisma version matching
  if (prisma !== @prisma/client) {
    issues.push({
      message: 'Prisma CLI and @prisma/client versions MUST match exactly.',
      severity: 'error'
    });
  }

  // React + React DOM matching
  if (react !== react-dom) {
    issues.push({
      message: 'React and React DOM versions MUST match exactly.',
      severity: 'error'
    });
  }

  // TypeScript types matching
  if (@types/react major !== react major) {
    issues.push({
      message: '@types/react version should match React major version.',
      severity: 'warning'
    });
  }

  return issues;
}
```

---

### Task 9.10: Integrate Compatibility Checking
**Estimated Effort**: Medium (6 hours)
**Files to Modify**:
- `packages/core/src/lib/tech-stack-suggester.ts`

**Purpose**: Run compatibility checks after validating individual packages.

**Implementation**:
```typescript
private async validateOptions(options: TechStackOption[]): Promise<TechStackOption[]> {
  for (const option of options) {
    // Step 1: Validate individual packages (existing code)
    const validationResults = await this.validator.validatePackages(npmPackages);

    // Step 2: Check compatibility between packages (NEW)
    const packageList = npmPackages.map(name => ({
      name: cleanPackageName(name),
      version: packageVersionMap.get(cleanPackageName(name)) || 'latest',
    }));

    const compatResult = await this.compatibilityChecker.checkCompatibility(packageList);

    // Step 3: Handle compatibility issues
    if (!compatResult.compatible) {
      console.log(`\n   ‚ö†Ô∏è  Compatibility issues in "${option.name}":\n`);

      compatResult.issues.forEach(issue => {
        console.log(`   ${issue.severity === 'error' ? '‚ùå' : '‚ö†Ô∏è'}  ${issue.message}`);
      });

      // Try to auto-fix
      if (compatResult.adjustedVersions) {
        console.log('\n   üîß Auto-adjusting versions...\n');
        compatResult.adjustedVersions.forEach((version, pkg) => {
          packageVersionMap.set(pkg, version);
          console.log(`      ${pkg}: ${version}`);
        });
        option.cons.push('‚ö†Ô∏è  Some versions were adjusted for compatibility');
      } else {
        // Can't auto-fix
        option.cons.unshift('‚ùå Has unresolvable compatibility issues');
        option.recommended = false;
      }
    } else {
      console.log(`   ‚úÖ All packages compatible in "${option.name}"\n`);
    }
  }

  return options;
}
```

---

### Task 9.11: Document Compatibility in tech-stack.md
**Estimated Effort**: Small (3 hours)
**Files to Modify**:
- `packages/core/src/lib/tech-stack-generator.ts`

**Purpose**: Include compatibility matrix and version constraints in tech-stack.md.

**Updated System Prompt**:
```typescript
const systemPrompt = `... existing prompt ...

ADDITIONAL REQUIREMENTS:
1. Include "Compatibility Matrix" section showing peer dependencies
2. Include "Version Constraints" section with critical matches
3. Include "Package Verification" section with validation dates
4. Keep total under 125 lines (be extremely concise)

Required sections:
## Compatibility Matrix
| Package | Version | Peer Dependencies | Status |
|---------|---------|-------------------|--------|
| next | 14.1.0 | react: ^18.2.0 or ^19.0.0 | ‚úÖ |

## Version Constraints
### Critical Exact Matches
- React + React DOM: 18.2.0 = 18.2.0 ‚úÖ
- Prisma CLI + Client: 5.8.0 = 5.8.0 ‚úÖ

### Compatibility Requirements
- Next.js 14: Supports React 18.2+ or React 19
- Tailwind 3: Requires PostCSS 8.x

## Package Verification
All packages verified on: 2026-01-02

| Package | Latest | Selected | Notes |
|---------|--------|----------|-------|
| next | 14.1.0 | 14.1.0 | ‚úÖ Latest stable |
| react | 19.0.0 | 18.2.0 | Staying on 18 for stability |
`;
```

**Example tech-stack.md Output**:
```markdown
# Tech Stack Summary

**Project**: Todo App
**Created**: 2026-01-02
**Last Validated**: 2026-01-02

## Frontend
- **Framework**: Next.js 14.1.0
- **UI Library**: React 18.2.0
- **Language**: TypeScript 5.3.3

## Compatibility Matrix

| Package | Version | Peer Dependencies | Status |
|---------|---------|-------------------|--------|
| next | 14.1.0 | react: ^18.2.0 or ^19.0.0 | ‚úÖ |
| react | 18.2.0 | - | ‚úÖ |
| react-dom | 18.2.0 | react: 18.2.0 (exact) | ‚úÖ |
| tailwindcss | 3.4.1 | postcss: ^8.0.0 | ‚úÖ |

## Version Constraints

### Critical Exact Matches
- React + React DOM: 18.2.0 = 18.2.0 ‚úÖ
- @types/react major: 18.x matches React 18.x ‚úÖ

### Compatibility Requirements
- Next.js 14: Supports React 18.2+ or React 19
- Tailwind CSS 3: Requires PostCSS 8.x (have 8.4.33 ‚úÖ)

### Upgrade Path
- React 18 ‚Üí 19: Requires Next.js 14.1+ (we have 14.1.0 ‚úÖ)

## Dependencies

```json
{
  "dependencies": {
    "next": "14.1.0",
    "react": "18.2.0",
    "react-dom": "18.2.0"
  },
  "devDependencies": {
    "typescript": "5.3.3",
    "@types/react": "18.2.48"
  }
}
```

## Maintenance Notes

**Last Compatibility Check**: 2026-01-02
**Next Check Recommended**: 2026-04-02 (quarterly)
```

---

## üéØ Success Criteria for Phase 9

### Package Validation
- [ ] Validates npm packages via registry API
- [ ] Validates PyPI packages via PyPI API
- [ ] Gets latest stable versions (excludes beta/alpha)
- [ ] Detects deprecated packages
- [ ] Suggests replacement packages for deprecated ones
- [ ] Checks package popularity (downloads/week)
- [ ] Checks package maintenance (last publish date)
- [ ] Displays clear warnings for deprecated/unmaintained packages

### Dependency Compatibility
- [ ] Validates peer dependencies for all packages
- [ ] Detects version conflicts (e.g., Next.js 13 + React 19)
- [ ] Auto-adjusts versions to compatible sets when possible
- [ ] Displays compatibility matrix
- [ ] Checks known incompatibilities (Next+React, Prisma, React+ReactDOM, etc.)
- [ ] Validates exact version matches where required
- [ ] Provides clear error messages for conflicts
- [ ] Suggests upgrade paths

### Tech Stack Selection
- [ ] Detects existing tech stack from package.json, tsconfig, etc.
- [ ] Distinguishes greenfield vs brownfield projects
- [ ] Suggests 3-4 relevant tech stack options based on PRD
- [ ] Displays options with pros/cons/best-for
- [ ] Allows user selection via interactive prompt
- [ ] Generates tech-stack.md (max 125 lines)
- [ ] Documents compatibility matrix in tech-stack.md
- [ ] Documents version constraints in tech-stack.md
- [ ] Uses tech stack context for architecture-rules.md generation
- [ ] Uses tech stack context for coding-standards.md generation
- [ ] Architecture rules are SPECIFIC to chosen stack (not generic)
- [ ] Blocks recommending stacks with deprecated packages
- [ ] Blocks recommending stacks with compatibility issues
- [ ] Web search integration for best practices (optional enhancement)

---

## üìä Updated Effort Estimates

| Phase | Tasks | Estimated Time | Priority |
|-------|-------|---------------|----------|
| **Phase 9** | **4** | **20 hours** | **CRITICAL** |
| Phase 1 | 2 | 3 hours | URGENT |
| Phase 2 | 3 | 6 hours | HIGH |
| Phase 3 | 3 | 8 hours | MEDIUM |
| Phase 4 | 2 | 8 hours | MEDIUM |
| Phase 6 | 3 | 6 hours | HIGH |
| Phase 7 | 4 | 16 hours | CRITICAL |
| Phase 8 | 2 | 3 hours | MEDIUM |

**Total Estimated Time**: ~70 hours (~8-9 days)

---

## üìù Updated Notes on Phase 9

**Why This is Critical**:
- Current generate-arch produces **useless generic rules** without tech stack knowledge
- **Blocks meaningful task generation** - tasks need stack-specific context
- PRD only describes WHAT, not HOW or WITH WHAT TECH

**Key Design Decisions**:
1. **tech-stack.md is the single source of truth** for all technology decisions
2. **Interactive selection** ensures user buy-in and correctness
3. **Web search integration** (future) keeps recommendations current
4. **Max 125 lines** keeps context manageable for task generation
5. **Brownfield detection** respects existing projects

**Integration with Other Phases**:
- Phase 9 must come **before** Phase 1 (can't generate good arch rules without stack)
- Phase 7 (streaming) would greatly improve UX of tech stack suggestion
- Phase 6 (token tracking) important for web search costs

---

**FINAL Priority Order**:
1. üî¥ **Phase 9**: Interactive tech stack (BLOCKS everything else)
2. üî¥ **Phase 7**: Streaming (best UX impact)
3. üî¥ **Phase 1**: Fix blocker + length limits
4. üü° **Phase 6**: Token tracking
5. üü° **Phase 8**: Task granularity
6. üü¢ **Phase 2, 3, 4**: Polish
